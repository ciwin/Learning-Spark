{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4881848c",
   "metadata": {},
   "source": [
    "# Chapter 10: Machine Learning with MLlib - Hyperparameter Tuning and Tree-Based Methods\n",
    "Christoph Windheuser    \n",
    "July, 2022   \n",
    "Python examples of chapter 10 (page 307 ff) in the book *Learning Spark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9750123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required python spark libraries\n",
    "import pyspark\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00366de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a SparkSession\n",
    "# This requires access to the internet. If executed offline, an error is thrown\n",
    "\n",
    "spark = (SparkSession \\\n",
    "         .builder \\\n",
    "         .appName(\"Chapter_10\") \\\n",
    "         .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382b851",
   "metadata": {},
   "source": [
    "# Reading and Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c0b1574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5780 rows in the training set, and 1366 rows in the test set.\n"
     ]
    }
   ],
   "source": [
    "filePath = \"../DB_Spark/LearningSparkV2/databricks-datasets/learning-spark-v2/sf-airbnb/sf-airbnb-clean.parquet\"\n",
    "airbnbDF = spark.read.parquet(filePath)\n",
    "\n",
    "trainDF, testDF = airbnbDF.randomSplit([0.8, 0.2], seed=42)\n",
    "print (f\"There are {trainDF.count()} rows in the training set, and {testDF.count()} rows in the test set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5af9f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalCols = [field for (field, dataType) in trainDF.dtypes if dataType == \"string\"]\n",
    "indexOutputCols = [x + \"Index\" for x in categoricalCols]\n",
    "# oheOutputCols   = [x + \"OHE\"   for x in categoricalCols]\n",
    "stringIndexer = StringIndexer(inputCols = categoricalCols,\n",
    "                             outputCols = indexOutputCols,\n",
    "                             handleInvalid=\"skip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b485588",
   "metadata": {},
   "source": [
    "# Build a Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a68ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(labelCol=\"price\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431d5ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for just numeric volumns and exclude price, our label\n",
    "numericCols = [field for (field, dataType) in trainDF.dtypes\n",
    "              if ((dataType == \"double\") & (field != \"price\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b0a7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine output of StringIndexer defined above and numeric columns\n",
    "assemblerInputs = indexOutputCols + numericCols\n",
    "vecAssembler    = VectorAssembler(inputCols = assemblerInputs, outputCol = \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29933467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine stages into pipeline\n",
    "stages   = [stringIndexer, vecAssembler, dt]\n",
    "pipeline = Pipeline(stages=stages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862b0ef6",
   "metadata": {},
   "source": [
    "### Tuning the Hyperparameter MaxBins\n",
    "Without the command `dt.setMaxBins(40)` the code would through an error that the paramter `MaxBins = 32`is too small. Seting `MaxBin`to 40 resloves this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4942ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training: \n",
    "dt.setMaxBins(40)                              # Without this command, an error is thrown\n",
    "pipelineModel = pipeline.fit(trainDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764c9b5",
   "metadata": {},
   "source": [
    "### Let us inspect the learned model and it's if-then-else rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8912a7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressionModel: uid=DecisionTreeRegressor_0a4c13755898, depth=5, numNodes=47, numFeatures=33\n",
      "  If (feature 12 <= 2.5)\n",
      "   If (feature 12 <= 1.5)\n",
      "    If (feature 5 in {1.0,2.0})\n",
      "     If (feature 4 in {0.0,1.0,3.0,5.0,9.0,10.0,11.0,13.0,14.0,16.0,18.0,24.0})\n",
      "      If (feature 3 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0})\n",
      "       Predict: 104.23992784125075\n",
      "      Else (feature 3 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,32.0,33.0,34.0})\n",
      "       Predict: 250.7111111111111\n",
      "     Else (feature 4 not in {0.0,1.0,3.0,5.0,9.0,10.0,11.0,13.0,14.0,16.0,18.0,24.0})\n",
      "      If (feature 3 in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,27.0,33.0,35.0})\n",
      "       Predict: 151.94179894179894\n",
      "      Else (feature 3 not in {0.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,20.0,21.0,22.0,23.0,27.0,33.0,35.0})\n",
      "       Predict: 245.8507462686567\n",
      "    Else (feature 5 not in {1.0,2.0})\n",
      "     If (feature 3 in {1.0,5.0,6.0,7.0,8.0,9.0,11.0,13.0,15.0,16.0,17.0,19.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\n",
      "      If (feature 3 in {5.0,8.0,13.0,15.0,16.0,19.0,22.0,23.0,24.0,25.0,28.0,30.0,33.0})\n",
      "       Predict: 131.96658097686375\n",
      "      Else (feature 3 not in {5.0,8.0,13.0,15.0,16.0,19.0,22.0,23.0,24.0,25.0,28.0,30.0,33.0})\n",
      "       Predict: 164.19959266802445\n",
      "     Else (feature 3 not in {1.0,5.0,6.0,7.0,8.0,9.0,11.0,13.0,15.0,16.0,17.0,19.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\n",
      "      If (feature 10 <= 6.5)\n",
      "       Predict: 205.5814889336016\n",
      "      Else (feature 10 > 6.5)\n",
      "       Predict: 841.6666666666666\n",
      "   Else (feature 12 > 1.5)\n",
      "    If (feature 13 <= 4.5)\n",
      "     If (feature 3 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,15.0,16.0,17.0,18.0,19.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,33.0,34.0})\n",
      "      If (feature 14 <= 26.5)\n",
      "       Predict: 290.8357933579336\n",
      "      Else (feature 14 > 26.5)\n",
      "       Predict: 214.04819277108433\n",
      "     Else (feature 3 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,9.0,10.0,11.0,12.0,13.0,15.0,16.0,17.0,18.0,19.0,22.0,23.0,24.0,25.0,26.0,27.0,28.0,29.0,30.0,31.0,33.0,34.0})\n",
      "      If (feature 14 <= 3.5)\n",
      "       Predict: 741.64\n",
      "      Else (feature 14 > 3.5)\n",
      "       Predict: 309.03921568627453\n",
      "    Else (feature 13 > 4.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      If (feature 2 in {1.0})\n",
      "       Predict: 300.0\n",
      "      Else (feature 2 not in {1.0})\n",
      "       Predict: 10000.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      If (feature 3 in {1.0,4.0,5.0,7.0,8.0,19.0})\n",
      "       Predict: 222.91666666666666\n",
      "      Else (feature 3 not in {1.0,4.0,5.0,7.0,8.0,19.0})\n",
      "       Predict: 398.0\n",
      "  Else (feature 12 > 2.5)\n",
      "   If (feature 1 in {0.0,1.0,2.0,3.0,4.0})\n",
      "    If (feature 12 <= 5.5)\n",
      "     If (feature 3 in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,10.0,11.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,21.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\n",
      "      If (feature 14 <= 7.5)\n",
      "       Predict: 493.3795620437956\n",
      "      Else (feature 14 > 7.5)\n",
      "       Predict: 296.76666666666665\n",
      "     Else (feature 3 not in {0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0,8.0,10.0,11.0,13.0,14.0,15.0,16.0,17.0,18.0,19.0,21.0,22.0,23.0,24.0,25.0,26.0,28.0,29.0,30.0,33.0})\n",
      "      If (feature 9 <= -122.411075)\n",
      "       Predict: 722.96875\n",
      "      Else (feature 9 > -122.411075)\n",
      "       Predict: 2399.4\n",
      "    Else (feature 12 > 5.5)\n",
      "     If (feature 4 in {0.0,1.0,5.0,7.0})\n",
      "      If (feature 3 in {0.0,3.0,6.0,25.0})\n",
      "       Predict: 609.5\n",
      "      Else (feature 3 not in {0.0,3.0,6.0,25.0})\n",
      "       Predict: 1715.0\n",
      "     Else (feature 4 not in {0.0,1.0,5.0,7.0})\n",
      "      Predict: 8000.0\n",
      "   Else (feature 1 not in {0.0,1.0,2.0,3.0,4.0})\n",
      "    Predict: 8000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtModel = pipelineModel.stages[-1]\n",
    "print(dtModel.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c2183",
   "metadata": {},
   "source": [
    "### Extract the Feature Importance Scores to find the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7877fd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>0.283406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cancellation_policyIndex</td>\n",
       "      <td>0.167893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instant_bookableIndex</td>\n",
       "      <td>0.140081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>property_typeIndex</td>\n",
       "      <td>0.128179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>0.126233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neighbourhood_cleansedIndex</td>\n",
       "      <td>0.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.038810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minimum_nights</td>\n",
       "      <td>0.029473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>beds</td>\n",
       "      <td>0.015218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>room_typeIndex</td>\n",
       "      <td>0.010905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>accommodates</td>\n",
       "      <td>0.003603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>host_is_superhostIndex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bathrooms_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>beds_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>review_scores_rating_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>review_scores_accuracy_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>review_scores_cleanliness_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>review_scores_value</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>review_scores_checkin_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>review_scores_communication_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>review_scores_location_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bedrooms_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>review_scores_rating</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>review_scores_location</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>review_scores_communication</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review_scores_checkin</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>review_scores_cleanliness</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>review_scores_accuracy</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>host_total_listings_count</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bed_typeIndex</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>review_scores_value_na</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           feature  importance\n",
       "12                        bedrooms    0.283406\n",
       "1         cancellation_policyIndex    0.167893\n",
       "2            instant_bookableIndex    0.140081\n",
       "4               property_typeIndex    0.128179\n",
       "15               number_of_reviews    0.126233\n",
       "3      neighbourhood_cleansedIndex    0.056200\n",
       "9                        longitude    0.038810\n",
       "14                  minimum_nights    0.029473\n",
       "13                            beds    0.015218\n",
       "5                   room_typeIndex    0.010905\n",
       "10                    accommodates    0.003603\n",
       "0           host_is_superhostIndex    0.000000\n",
       "24                    bathrooms_na    0.000000\n",
       "25                         beds_na    0.000000\n",
       "26         review_scores_rating_na    0.000000\n",
       "27       review_scores_accuracy_na    0.000000\n",
       "28    review_scores_cleanliness_na    0.000000\n",
       "22             review_scores_value    0.000000\n",
       "29        review_scores_checkin_na    0.000000\n",
       "30  review_scores_communication_na    0.000000\n",
       "31       review_scores_location_na    0.000000\n",
       "23                     bedrooms_na    0.000000\n",
       "16            review_scores_rating    0.000000\n",
       "21          review_scores_location    0.000000\n",
       "20     review_scores_communication    0.000000\n",
       "19           review_scores_checkin    0.000000\n",
       "18       review_scores_cleanliness    0.000000\n",
       "17          review_scores_accuracy    0.000000\n",
       "11                       bathrooms    0.000000\n",
       "8                         latitude    0.000000\n",
       "7        host_total_listings_count    0.000000\n",
       "6                    bed_typeIndex    0.000000\n",
       "32          review_scores_value_na    0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureImp = pd.DataFrame(list(zip(vecAssembler.getInputCols(), dtModel.featureImportances)),\n",
    "                          columns=[\"feature\", \"importance\"])\n",
    "featureImp.sort_values(by=\"importance\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885ddff8",
   "metadata": {},
   "source": [
    "### Calculating RMSE and R<sup>2</sup> for the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01d1ac1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "| price|        prediction|\n",
      "+------+------------------+\n",
      "|  85.0|131.96658097686375|\n",
      "|  45.0|104.23992784125075|\n",
      "|  70.0|104.23992784125075|\n",
      "| 128.0|104.23992784125075|\n",
      "| 159.0|104.23992784125075|\n",
      "| 250.0| 290.8357933579336|\n",
      "|  99.0| 205.5814889336016|\n",
      "|  95.0|131.96658097686375|\n",
      "| 100.0|104.23992784125075|\n",
      "|2010.0| 205.5814889336016|\n",
      "+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predDF = pipelineModel.transform(testDF)\n",
    "predDF.select(\"price\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eef89824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is 385.9\n"
     ]
    }
   ],
   "source": [
    "regressionEvaluator = RegressionEvaluator (\n",
    "    predictionCol = \"prediction\",\n",
    "    labelCol      = \"price\",\n",
    "    metricName    = \"rmse\")\n",
    "\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "print (f\"RMSE is {rmse:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75345d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 is -1.5696388432265533\n"
     ]
    }
   ],
   "source": [
    "regressionEvaluator = RegressionEvaluator (\n",
    "    predictionCol = \"prediction\",\n",
    "    labelCol      = \"price\",\n",
    "    metricName    = \"r2\")\n",
    "\n",
    "r2 = regressionEvaluator.evaluate(predDF)\n",
    "print (f\"R^2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba532a22",
   "metadata": {},
   "source": [
    "### Results\n",
    "The Decision Tree model performs worse than the linear regression models and even worse than our baseline model based on the average:    \n",
    "\n",
    "Model | RMSE <br/> *(lower is better)* | R<sup>2</sup> <br/> *(higher is better)*\n",
    ":---|:---|:---\n",
    "Baseline (avg.) | 240.8 | -0.001\n",
    "linear price    | 220.6 | 0.160\n",
    "log price       | 208.2 | 0.252\n",
    "Decision Tree   | 385.9 | -1.570\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d124ed",
   "metadata": {},
   "source": [
    "# Random Forests\n",
    "Page 313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3e202a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(labelCol=\"price\", maxBins=40, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8d6895f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[stringIndexer, vecAssembler, rf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4b65412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.maxDepth, [2, 4, 6])\n",
    "             .addGrid(rf.numTrees, [10, 100])\n",
    "             .build())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4cd23211",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"price\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9307b0aa",
   "metadata": {},
   "source": [
    "### Training our model with k-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3cb3844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 22.146804809570312 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "import time\n",
    "\n",
    "cv = CrossValidator(estimator          = pipeline,\n",
    "                    evaluator          = evaluator,\n",
    "                    estimatorParamMaps = paramGrid,\n",
    "                    numFolds           = 3,\n",
    "                    seed               = 42)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "cvModel = cv.fit(trainDF)\n",
    "print(\"--- Command took %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330e891",
   "metadata": {},
   "source": [
    "### Inspect the Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6509ef09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({Param(parent='RandomForestRegressor_dc8c089f32e3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n",
       "   Param(parent='RandomForestRegressor_dc8c089f32e3', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  291.18226409247836),\n",
       " ({Param(parent='RandomForestRegressor_dc8c089f32e3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 2,\n",
       "   Param(parent='RandomForestRegressor_dc8c089f32e3', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  286.7714750274078),\n",
       " ({Param(parent='RandomForestRegressor_dc8c089f32e3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n",
       "   Param(parent='RandomForestRegressor_dc8c089f32e3', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  287.6963245160818),\n",
       " ({Param(parent='RandomForestRegressor_dc8c089f32e3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 4,\n",
       "   Param(parent='RandomForestRegressor_dc8c089f32e3', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  279.99270572360797),\n",
       " ({Param(parent='RandomForestRegressor_dc8c089f32e3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n",
       "   Param(parent='RandomForestRegressor_dc8c089f32e3', name='numTrees', doc='Number of trees to train (>= 1).'): 10},\n",
       "  294.34810870889305),\n",
       " ({Param(parent='RandomForestRegressor_dc8c089f32e3', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 6,\n",
       "   Param(parent='RandomForestRegressor_dc8c089f32e3', name='numTrees', doc='Number of trees to train (>= 1).'): 100},\n",
       "  275.3986270472998)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cvModel.getEstimatorParamMaps(), cvModel.avgMetrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abda51",
   "metadata": {},
   "source": [
    "### Parallelize Training in Spark\n",
    "Page 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb15b2ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Command took 13.251630067825317 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "cvModel    = cv.setParallelism(4).fit(trainDF)\n",
    "print(\"--- Command took %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d4f7e",
   "metadata": {},
   "source": [
    "### Further Improve Performance by putting the cross-validator inside the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee46bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Command took 11.37712812423706 seconds ---\n"
     ]
    }
   ],
   "source": [
    "cv = CrossValidator(estimator          = rf,\n",
    "                    evaluator          = evaluator,\n",
    "                    estimatorParamMaps = paramGrid,\n",
    "                    numFolds           = 3,\n",
    "                    parallelism        = 4,\n",
    "                    seed               = 42)\n",
    "\n",
    "pipeline = Pipeline(stages=[stringIndexer, vecAssembler, cv])\n",
    "\n",
    "start_time    = time.time()\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "print(\"--- Command took %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0aee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
