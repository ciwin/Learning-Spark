{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4575dc30",
   "metadata": {},
   "source": [
    "# Chapter 8: Structured Streaming\n",
    "Christoph Windheuser    \n",
    "May, 2022   \n",
    "Python examples of chapter 8 (page 207 ff) in the book *Learning Spark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deab6a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required python spark libraries\n",
    "import pyspark\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7687e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a SparkSession\n",
    "\n",
    "spark = (SparkSession \\\n",
    "         .builder \\\n",
    "         .enableHiveSupport() \\\n",
    "         .appName(\"Chapter_7\") \\\n",
    "         .getOrCreate())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8595d3f",
   "metadata": {},
   "source": [
    "# Create a stream\n",
    "Run the command `nc -lk 9999`in a terminal window.    \n",
    "All text you type into the terminal will be send as a data stream to port 9999 whenever you hit `Return`.    \n",
    "`nc` stands for *Netcat* and is a simple computer network utility available under Linux, macOS and Windows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb5ee4",
   "metadata": {},
   "source": [
    "# Example of Reading a stream of data\n",
    "Creating a DataFrame from a text data stream to be received over a socket connection on a localhost. Do a continuous word count on the streaming data and print the results to the console.\n",
    "\n",
    "Whenever text is typed into the `nc` command in the terminal, the tesxt is processed and the word count is printed out in the console of the Jupyter notebook until the spark command `streamingQuery.stop()` is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46289248",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (spark\n",
    "         .readStream.format(\"socket\")\n",
    "         .option(\"host\", \"localhost\")\n",
    "         .option(\"port\", \"9999\")\n",
    "         .load()\n",
    ")\n",
    "\n",
    "words  = lines.select(split(col(\"value\"), \"\\\\s\").alias(\"word\"))\n",
    "counts = words.groupBy(\"word\").count()\n",
    "\n",
    "checkpointDir = \"/tmp/checkpoints\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109ef0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "streamingQuery = (counts\n",
    "                 .writeStream\n",
    "                 .format(\"console\")\n",
    "                 .outputMode(\"complete\")\n",
    "                 .trigger(processingTime=\"2 second\")\n",
    "                 .option(\"checkpointLocation\", checkpointDir)\n",
    "                 .start()\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad15f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the Streaming Query:\n",
    "streamingQuery.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cac6676",
   "metadata": {},
   "source": [
    "## Example:\n",
    "https://spark.apache.org/docs/latest/streaming-programming-guide.html\n",
    "and:\n",
    "https://github.com/apache/spark/blob/v3.2.1/examples/src/main/python/streaming/network_wordcount.py\n",
    "\n",
    "1. Run the program `nc -lk 9999` in a terminal.    \n",
    "   This program sends all text entered in the terminal out via port 9999\n",
    "2. Run the program `spark-submit network_wordcount.py localhost 9999` in another terminal.\n",
    "3. Each time words are typed in the first terminal, the words are counted in the second terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ccde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It also works when the program is executed inside the Jupyter Notebook!\n",
    "# Run nc -lk 9999 in another terminal and type some text.\n",
    "# You will see the word count as output of this program in this \n",
    "# Jupyter Notebook!\n",
    "#\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "ssc = StreamingContext(sc, 1)\n",
    "\n",
    "lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "counts = lines.flatMap(lambda line: line.split(\" \"))\\\n",
    "                  .map(lambda word: (word, 1))\\\n",
    "                  .reduceByKey(lambda a, b: a+b)\n",
    "counts.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc967f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
